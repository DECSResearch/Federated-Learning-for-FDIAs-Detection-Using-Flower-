{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load the dataset\n",
    "data1 = pd.read_csv('V1_23_Feb_180m_anomalous_data(gaussian).csv')\n",
    "dataframe = data1\n",
    "\n",
    "dataframe['datetimestamp'] = pd.to_datetime(dataframe['datetimestamp'])\n",
    "\n",
    "# Take only 'datetimestamp', 'Hz_mod_anomaly', and 'mod_BIN' columns\n",
    "df = dataframe[['datetimestamp', 'Hz_mod_anomaly', 'mod_BIN']]\n",
    "df.set_index('datetimestamp', inplace=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6)) \n",
    "plt.plot(df.index, df['Hz_mod_anomaly'], label='Hz_mod_anomaly', color='blue')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.gcf().set_facecolor('white')\n",
    "plt.xlabel('Date Timestamp')\n",
    "plt.ylabel('Hz Mod Anomaly')\n",
    "plt.title('Anomalous Hz Over Time')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# print start and end date\n",
    "print(\"start date is:\", df.index.min())\n",
    "print(\"end date is:\", df.index.max())\n",
    "# Now we have to choose train and test sets \n",
    "# We will train LSTM autoencoders using only normal dataset which is labeled as 0 in the dataframe we have to separate normal from anomalous data.\n",
    "\n",
    "# Separate normal data (label 0) from anomalous data\n",
    "normal_data = df[df['mod_BIN'] == 0]\n",
    "anomalous_data = df[df['mod_BIN'] != 0]\n",
    "\n",
    "# Print start and end dates of normal data\n",
    "print(\"Start date of normal data is:\", normal_data.index.min())\n",
    "print(\"End date of normal data is:\", normal_data.index.max())\n",
    "\n",
    "# Print start and end dates of anomalous data\n",
    "print(\"Start date of anomalous data is:\", anomalous_data.index.min())\n",
    "print(\"End date of anomalous data is:\", anomalous_data.index.max())\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "703643f4f39749d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Now we make train and test dataset\n",
    "# in this case 80 % of normal data would be used for training and rest 20% of normal data + all anomalous data would be used in test \n",
    "\n",
    "start_anomalous_date = anomalous_data.index.min()\n",
    "\n",
    "# Split normal data into train before anomaly and train after anomaly\n",
    "train_before_anomaly = normal_data[normal_data.index < start_anomalous_date]\n",
    "train_after_anomaly = normal_data[normal_data.index >= start_anomalous_date]\n",
    "\n",
    "# Calculate the number of rows for 80% of normal data\n",
    "train_normal_size = int(0.8 * len(normal_data))\n",
    "\n",
    "# Select the first 80% of normal data for training\n",
    "train = normal_data.iloc[:train_normal_size]\n",
    "\n",
    "# Select the remaining 20% of normal data for testing\n",
    "test_normal = normal_data.iloc[train_normal_size:]\n",
    "\n",
    "# Concatenate test normal data with anomalous data\n",
    "test = pd.concat([test_normal, anomalous_data])\n",
    "\n",
    "print(\"Shape of train:\", train.shape)\n",
    "print(\"Shape of test:\", test.shape)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))  # Adjust the figure size if needed\n",
    "sns.lineplot(x='datetimestamp', y='Hz_mod_anomaly', data=train_before_anomaly, label='Train Data', color='blue')\n",
    "sns.lineplot(x='datetimestamp', y='Hz_mod_anomaly', data=train_after_anomaly, color='blue')\n",
    "sns.lineplot(x='datetimestamp', y='Hz_mod_anomaly', data=test_normal, color='red')\n",
    "sns.lineplot(x='datetimestamp', y='Hz_mod_anomaly', data=anomalous_data, label='Test Data', color='red')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Hz_mod_anomaly')\n",
    "plt.title('Train vs Test Data')\n",
    "plt.legend()\n",
    "plt.gca().set_facecolor('white')\n",
    "plt.gcf().set_facecolor('white')\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae2a68d498a95444"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Since LSTM use sigmoid and tanh so we need out values to be normalized , we will use Standard Scaler for that\n",
    "# \n",
    "# scaler = StandardScaler()\n",
    "# scaler = scaler.fit(train[['Hz_mod_anomaly']])\n",
    "# \n",
    "# train.loc[:, 'Hz_mod_anomaly'] = scaler.transform(train[['Hz_mod_anomaly']])\n",
    "# test.loc[:, 'Hz_mod_anomaly'] = scaler.transform(test[['Hz_mod_anomaly']])\n",
    "\n",
    "# Drop the 'mod_BIN' column from train and test DataFrames because it was just labels to split between train and test \n",
    "train = train.drop(columns=['mod_BIN'])\n",
    "test = test.drop(columns=['mod_BIN'])\n",
    "\n",
    "# Display the first few rows of train and test sets\n",
    "print(train.head())\n",
    "print(test.head())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85102876a9194a0d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "seq_size = 20 # Number of time steps to look back \n",
    "# larger sequence size (look further back) may improve forecasting \n",
    "\n",
    "def to_sequence(x, y, seq_size=1):\n",
    "    x_values = []\n",
    "    y_values = []\n",
    "    \n",
    "    for i in range(len(x)-seq_size):\n",
    "        #print(i)\n",
    "        x_values.append(x.iloc[i:(i+seq_size)].values)\n",
    "        y_values.append(y.iloc[i+seq_size])\n",
    "        \n",
    "    return np.array(x_values), np.array(y_values)\n",
    "\n",
    "trainX, trainY = to_sequence(train[['Hz_mod_anomaly']], train['Hz_mod_anomaly'], seq_size)\n",
    "testX, testY = to_sequence(test[['Hz_mod_anomaly']], test['Hz_mod_anomaly'], seq_size)\n",
    "\n",
    "print(\"train X shape\", trainX.shape)\n",
    "print(\"train Y shape\", trainY.shape)\n",
    "print(\"test X shape\", testX.shape)\n",
    "print(\"test Y shape\", testY.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21fc78bc2d25f4a6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, RepeatVector, TimeDistributed, Dense\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, activation='tanh', recurrent_activation='sigmoid', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(64, activation='tanh', recurrent_activation='sigmoid', return_sequences=False))\n",
    "model.add(RepeatVector(trainX.shape[1]))\n",
    "model.add(LSTM(64, activation='tanh', recurrent_activation='sigmoid', return_sequences=True))\n",
    "model.add(LSTM(128, activation='tanh', recurrent_activation='sigmoid', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(trainX.shape[2])))\n",
    "model.compile(optimizer='adam', loss='mae', metrics=[\"mape\"])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mae', metrics=[\"mape\"])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e11468c30890134"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Measure the time\n",
    "start_training_time = time.time()\n",
    "# Fit the model\n",
    "history = model.fit(trainX, trainY, epochs=35, batch_size=100, validation_split=0.2, verbose=1)\n",
    "end_training_time = time.time()\n",
    "training_time = end_training_time - start_training_time\n",
    "print(f\"Total training time: {training_time:.2f} seconds\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ad6bd6a232abcd4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# training history\n",
    "training_loss = history.history['loss']\n",
    "training_mape = history.history['mape']\n",
    "val_loss = history.history['val_loss']\n",
    "val_mape = history.history['val_mape']\n",
    "epochs = range(1, len(training_loss) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot training and validation loss \n",
    "plt.plot(epochs, training_loss, color='blue', label='Training loss')\n",
    "plt.plot(epochs, val_loss, color='green', label='Validation loss')\n",
    "\n",
    "# Plot training and validation MAPE \n",
    "plt.plot(epochs, training_mape, color='orange', linestyle='--', label='Training MAPE')\n",
    "plt.plot(epochs, val_mape, color='red', linestyle='--', label='Validation MAPE')\n",
    "\n",
    "plt.title('Training and Validation Loss / MAPE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss / MAPE')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Extract the final loss and MAPE values\n",
    "final_training_loss = training_loss[-1]\n",
    "final_val_loss = val_loss[-1]\n",
    "final_training_mape = training_mape[-1]\n",
    "final_val_mape = val_mape[-1]\n",
    "\n",
    "# Print the final loss and MAPE values\n",
    "print(\"Final Training Loss:\", final_training_loss)\n",
    "print(\"Final Validation Loss:\", final_val_loss)\n",
    "print(\"Final Training MAPE:\", final_training_mape)\n",
    "print(\"Final Validation MAPE:\", final_val_mape)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73d2254c845893cd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# When reconstruction error (MAPE) is larger than the threshold which we set then there is anomaly\n",
    "\n",
    "# Calculate MAE for training prediction\n",
    "trainPredict = model.predict(trainX)\n",
    "trainMAE = np.mean(np.abs(trainPredict - trainX), axis=1)\n",
    "# Print the mean of test MAE\n",
    "print(\"Mean of Train MAE:\", np.mean(trainMAE))\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(trainMAE, bins=30)\n",
    "plt.xlabel('Mean Absolute Error (MAE)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Mean Absolute Error (MAE) in Training Prediction')\n",
    "plt.show()\n",
    "\n",
    "# Calculate MAPE for each sample\n",
    "trainActual = trainX  # Assuming trainX contains the actual values\n",
    "trainMAPE = np.mean(np.abs(trainPredict - trainActual) / trainActual, axis=1) * 100\n",
    "\n",
    "# Print the mean of MAPE\n",
    "print(\"Mean of Train MAPE:\", np.mean(trainMAPE))\n",
    "\n",
    "# Plot histogram of MAPE\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(trainMAPE, bins=30)\n",
    "plt.xlabel('Mean Absolute Percentage Error (MAPE)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Mean Absolute Percentage Error (MAPE) in Training Prediction')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca894b02ed77ab0d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate reconstruction loss (MAE) for testing dataset\n",
    "testPredict = model.predict(testX)\n",
    "testMAE = np.mean(np.abs(testPredict - testX), axis=1)\n",
    "\n",
    "# Print the mean of test MAE\n",
    "print(\"Mean of Test MAE:\", np.mean(testMAE))\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(testMAE, bins=30)\n",
    "plt.xlabel('Test MAE')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Test MAE')\n",
    "plt.show()\n",
    "\n",
    "# Calculate MAPE for each sample\n",
    "testActual = testX  # Assuming trainX contains the actual values\n",
    "testMAPE = np.mean(np.abs(testPredict - testActual) / testActual, axis=1) * 100\n",
    "\n",
    "# Print the mean of MAPE\n",
    "print(\"Mean of Test MAPE:\", np.mean(testMAPE))\n",
    "\n",
    "# Plot histogram of MAPE\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(testMAPE, bins=30)\n",
    "plt.xlabel('Mean Absolute Percentage Error (MAPE)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Mean Absolute Percentage Error (MAPE) in test Prediction')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a1b0dcf7d28c729"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "max_trainMAE = 0.76\n",
    "max_trainMAPE = 0.1\n",
    "# thresholding using MAPE \n",
    "anomaly_df = pd.DataFrame(test[seq_size:])\n",
    "anomaly_df['testMAPE'] = testMAPE\n",
    "anomaly_df['max_trainMAPE'] = max_trainMAPE\n",
    "anomaly_df['anomaly'] = anomaly_df['testMAPE'] > anomaly_df['max_trainMAPE']\n",
    "anomaly_df['Hz_mod_anomaly'] = test[seq_size:]['Hz_mod_anomaly']\n",
    "\n",
    "# Plot test MAE vs max_trainMAE\n",
    "sns.lineplot(x=anomaly_df.index, y=anomaly_df['testMAPE'])\n",
    "sns.lineplot(x=anomaly_df.index, y=anomaly_df['max_trainMAPE'])\n",
    "plt.xticks(rotation=45)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32b39d4e0c3a1ca2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Extract anomalies DataFrame with 'anomaly' column equal to True\n",
    "anomalies = anomaly_df.loc[anomaly_df['anomaly'] == True]\n",
    "# \n",
    "# # Reshape the 'Hz_mod_anomaly' column to be a 2-dimensional array\n",
    "# hz_mod_anomaly_reshaped = scaler.inverse_transform(anomaly_df['Hz_mod_anomaly'].values.reshape(-1, 1))\n",
    "# \n",
    "# # Reshape the anomalies 'Hz_mod_anomaly' column to be a 2-dimensional array\n",
    "# anomalies_reshaped = scaler.inverse_transform(anomalies['Hz_mod_anomaly'].values.reshape(-1, 1))\n",
    "# \n",
    "# # Plot the data\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.lineplot(x=anomaly_df.index, y=hz_mod_anomaly_reshaped.flatten(), color='blue')  # Flatten to convert 2D array to 1D array\n",
    "# sns.scatterplot(x=anomalies.index, y=anomalies_reshaped.flatten(), color='red')  # Flatten to convert 2D array to 1D array\n",
    "# \n",
    "# # Show plot\n",
    "# plt.show()\n",
    "\n",
    "# Reshape the 'Hz_mod_anomaly' column to be a 2-dimensional array\n",
    "hz_mod_anomaly_reshaped = anomaly_df['Hz_mod_anomaly'].values.reshape(-1, 1)\n",
    "\n",
    "# Reshape the anomalies 'Hz_mod_anomaly' column to be a 2-dimensional array\n",
    "anomalies_reshaped = anomalies['Hz_mod_anomaly'].values.reshape(-1, 1)\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x=anomaly_df.index, y=hz_mod_anomaly_reshaped.flatten(), color='blue') \n",
    "sns.scatterplot(x=anomalies.index, y=anomalies_reshaped.flatten(), color='red')  \n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3fc92a8df8ddcbf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.metrics import mean_absolute_percentage_error, confusion_matrix\n",
    "\n",
    "# Load the dataset(s)\n",
    "# Adjust the path to your dataset file\n",
    "data1 = pd.read_csv('V3S3.csv')  # Replace 'V3S1.csv' with the correct file path if needed\n",
    "\n",
    "# Combine the datasets (if you have more)\n",
    "combined_data = pd.concat([data1], ignore_index=True)\n",
    "\n",
    "# Preprocess the combined dataset\n",
    "combined_data['datetimestamp'] = pd.to_datetime(combined_data['datetimestamp'])\n",
    "\n",
    "# Plot the combined dataset\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x='datetimestamp', y='Hz_mod_anomaly', data=combined_data)\n",
    "plt.xticks(rotation=45)\n",
    "plt.gcf().set_facecolor('white') \n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.title('Testing Dataset Version 3 Signature 1')\n",
    "plt.show()\n",
    "\n",
    "# Convert the combined dataset into sequences\n",
    "combined_X, combined_Y = to_sequence(combined_data[['Hz_mod_anomaly']], combined_data['Hz_mod_anomaly'], seq_size)\n",
    "\n",
    "# Measure the time before starting the prediction\n",
    "start_time = time.time()\n",
    "\n",
    "# Use the trained model to predict the reconstruction errors (MAPE) on the combined dataset\n",
    "combined_predict = model.predict(combined_X)\n",
    "\n",
    "# Measure the time after prediction\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate total inference time\n",
    "inference_time = end_time - start_time\n",
    "print(f\"Total inference time: {inference_time:.2f} seconds\")\n",
    "\n",
    "# Calculate combined MAPE\n",
    "combined_mape = np.mean(np.abs(combined_predict - combined_X) / combined_X, axis=1) * 100\n",
    "\n",
    "# Thresholding using MAPE\n",
    "max_trainMAPE = 0.1\n",
    "\n",
    "# Capture all details in a DataFrame for easy plotting\n",
    "anomaly_df = pd.DataFrame(combined_data[seq_size:])\n",
    "anomaly_df['combinedMAPE'] = combined_mape\n",
    "anomaly_df['max_trainMAPE'] = max_trainMAPE\n",
    "anomaly_df['anomaly'] = anomaly_df['combinedMAPE'] > max_trainMAPE\n",
    "anomaly_df['Hz_mod_anomaly'] = combined_data[seq_size:]['Hz_mod_anomaly']\n",
    "\n",
    "# Plot combined MAPE vs max_trainMAPE\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x=anomaly_df.index, y=anomaly_df['combinedMAPE'], label='MAPE')\n",
    "sns.lineplot(x=anomaly_df.index, y=anomaly_df['max_trainMAPE'], label='Threshold', linestyle='--')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Mean Absolute Percentage Error (MAPE)')\n",
    "plt.title('Anomaly Detection on Testing Dataset (V3-S2)')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Identify anomalies based on the threshold\n",
    "combined_anomalies = anomaly_df[anomaly_df['anomaly'] == True]\n",
    "\n",
    "# Plot anomalies\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x=combined_data['datetimestamp'], y=combined_data['Hz_mod_anomaly'], color='blue', label='Normal Data')\n",
    "sns.scatterplot(x=combined_anomalies['datetimestamp'], y=combined_anomalies['Hz_mod_anomaly'], color='red', label='Anomalies')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.title('Anomaly Detection on Testing Dataset (V3-S2)')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Get the true labels\n",
    "true_labels = (combined_data['mod_BIN'][seq_size:] != 0).astype(int)\n",
    "\n",
    "# confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, combined_mape > max_trainMAPE)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Anomaly'], yticklabels=['Normal', 'Anomaly'])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "TP = conf_matrix[1, 1]\n",
    "FP = conf_matrix[0, 1]\n",
    "TN = conf_matrix[0, 0]\n",
    "FN = conf_matrix[1, 0]\n",
    "\n",
    "# Print the counts\n",
    "print(\"True Positives (Anomalies correctly predicted as anomalies):\", TP)\n",
    "print(\"False Positives (Normal data incorrectly predicted as anomalies):\", FP)\n",
    "print(\"True Negatives (Normal data correctly predicted as normal):\", TN)\n",
    "print(\"False Negatives (Anomalies incorrectly predicted as normal):\", FN)\n",
    "\n",
    "# Calculate Precision, Recall, and F1-score\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1_score)\n",
    "accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Total inference time: {inference_time:.2f} seconds\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8472ca84f80ed38"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
